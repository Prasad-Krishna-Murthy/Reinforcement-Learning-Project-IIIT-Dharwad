# Reinforcement-Learning-Project-IIIT-Dharwad
A project showcasing an educational application with SLM using PPO and veRL

# Task
- Train a Small Language Model (SLM) **microsoft/DialoGPT-small** as an intelligent tutoring assistant
- Answer student questions accurately with educational explanations
- Adapt responses based on student level and question context
- Improve response quality through Reinforcement Learning (PPO)

# Training Dataset
- Size: 5-10 educational Q&A pairs (expandable)
- Content: Science, math, physics concepts at beginner/intermediate levels
- Structure:
- Question: "What is photosynthesis?"
- Expected response: Detailed educational explanation
- Context: Subject and difficulty level
- Sources: Custom educational content, textbook explanations

# RL Model Building Steps
- Environment Setup: Custom Gym environment for text generation
- Base Model: Initialize DialoGPT-small as starting SLM
- Action Space: Token sequences for response generation
- Observation Space: Question embeddings (384-dimensional)
- PPO Configuration:
- Learning rate: 1e-4 to 1e-6
- Gamma: 0.99, GAE lambda: 0.95
- Clip range: 0.2
- Training Loop: Collect trajectories â†’ Compute advantages â†’ Policy updates

# Reward Model
- Multi-component reward function:
- Semantic Similarity (60-70%): Cosine similarity between generated and expected responses
- Factual Accuracy (20-30%): Keyword matching and content verification
- Readability/Pedagogical Quality (10-20%):
- Response length appropriateness
- Explanation clarity
- Student level adaptation

# Training Progression
text
Epoch 1/5 | Reward: 0.15 â†’ 0.32 | Similarity: 0.12 â†’ 0.28
Epoch 2/5 | Reward: 0.35 â†’ 0.48 | Similarity: 0.30 â†’ 0.42
Epoch 3/5 | Reward: 0.50 â†’ 0.61 | Similarity: 0.45 â†’ 0.55
Epoch 4/5 | Reward: 0.63 â†’ 0.72 | Similarity: 0.58 â†’ 0.67
Epoch 5/5 | Reward: 0.75 â†’ 0.79 | Similarity: 0.70 â†’ 0.73

[Training Metrics]
- Initial responses: Short, generic, low accuracy
- Mid-training: Longer, more relevant, better structure  
- Final: Concise, accurate, educational explanations

# Accuracy Testing Results
text
ðŸ“Š PERFORMANCE METRICS:
- Semantic Similarity: 0.72 â†—
- Factual Accuracy: 0.68 â†—
- Response Quality: 0.75 â†—
- Overall Score: 0.72 (GOOD)

ðŸŽ¯ TESTING BREAKDOWN:
- Science Questions: 78% accuracy
- Math Problems: 65% accuracy  
- Conceptual Explanations: 73% accuracy
- Beginner Level: 82% appropriate
- Intermediate Level: 63% appropriate
# Key Achievement: Model learns to generate educational responses that are 72% similar to expert explanations while maintaining factual accuracy and pedagogical quality.
