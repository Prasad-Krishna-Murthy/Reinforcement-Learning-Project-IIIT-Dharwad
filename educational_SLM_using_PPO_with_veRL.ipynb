{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. Installation and Setup with veRL"
      ],
      "metadata": {
        "id": "dFG748Z_vnp1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLKYC4GvvZI9",
        "outputId": "2c67b6cc-3a19-437e-a681-21eb3ece2b88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping vel-rl as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping vel as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: stable-baselines3 in /usr/local/lib/python3.12/dist-packages (2.7.0)\n",
            "Requirement already satisfied: gymnasium<1.3.0,>=0.29.1 in /usr/local/lib/python3.12/dist-packages (from stable-baselines3) (1.2.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.12/dist-packages (from stable-baselines3) (2.0.2)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.12/dist-packages (from stable-baselines3) (2.8.0+cu126)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from stable-baselines3) (3.1.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from stable-baselines3) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from stable-baselines3) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium<1.3.0,>=0.29.1->stable-baselines3) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium<1.3.0,>=0.29.1->stable-baselines3) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.20.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->stable-baselines3) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->stable-baselines3) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3.0,>=2.3->stable-baselines3) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3.0,>=2.3->stable-baselines3) (3.0.3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.12/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.12/dist-packages (from gym) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gym) (3.1.2)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.12/dist-packages (from gym) (0.1.0)\n"
          ]
        }
      ],
      "source": [
        "# First, let's try to install veRL correctly\n",
        "# !pip uninstall -y vel-rl vel  # Clean any existing installations\n",
        "!pip install git+https://github.com/facebookresearch/vel.git # Commented out due to git clone error\n",
        "\n",
        "# If the above doesn't work, let's use a more reliable approach\n",
        "!pip install stable-baselines3\n",
        "!pip install gym\n",
        "!pip install shimmy>=0.2.1 # Install shimmy for Gym compatibility with Stable-Baselines3\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from datasets import Dataset\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import random\n",
        "import gym\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from stable_baselines3.common.callbacks import BaseCallback"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Create Education Dataset"
      ],
      "metadata": {
        "id": "hEq4VdctzVSd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_education_dataset():\n",
        "    data = [\n",
        "        {\n",
        "            \"question\": \"What is photosynthesis?\",\n",
        "            \"expected_response\": \"Photosynthesis is the process where plants use sunlight, water and carbon dioxide to create oxygen and energy in the form of sugar.\",\n",
        "            \"difficulty\": \"beginner\"\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"Solve 2x + 5 = 15\",\n",
        "            \"expected_response\": \"First, subtract 5 from both sides: 2x = 10. Then divide both sides by 2: x = 5\",\n",
        "            \"difficulty\": \"intermediate\"\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"What is Newton's first law of motion?\",\n",
        "            \"expected_response\": \"Newton's first law states that an object at rest stays at rest and an object in motion stays in motion with the same speed and in the same direction unless acted upon by an unbalanced force.\",\n",
        "            \"difficulty\": \"intermediate\"\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"Explain the water cycle\",\n",
        "            \"expected_response\": \"The water cycle describes how water evaporates from the Earth's surface, rises into the atmosphere, cools and condenses into rain or snow in clouds, and falls again to the surface as precipitation.\",\n",
        "            \"difficulty\": \"beginner\"\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"What is the Pythagorean theorem?\",\n",
        "            \"expected_response\": \"The Pythagorean theorem states that in a right triangle, the square of the hypotenuse is equal to the sum of the squares of the other two sides: a¬≤ + b¬≤ = c¬≤\",\n",
        "            \"difficulty\": \"intermediate\"\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"What causes seasons on Earth?\",\n",
        "            \"expected_response\": \"Seasons are caused by the tilt of Earth's axis as it orbits the Sun, not by changes in distance from the Sun.\",\n",
        "            \"difficulty\": \"intermediate\"\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"How do plants reproduce?\",\n",
        "            \"expected_response\": \"Plants can reproduce sexually through flowers and seeds, or asexually through methods like runners, bulbs, or cuttings.\",\n",
        "            \"difficulty\": \"beginner\"\n",
        "        }\n",
        "    ]\n",
        "    return Dataset.from_list(data)\n",
        "\n",
        "education_dataset = create_education_dataset()\n",
        "print(\"Education dataset created with\", len(education_dataset), \"samples\")\n",
        "print(\"\\nSample data:\")\n",
        "for i in range(2):\n",
        "    print(f\"Q: {education_dataset[i]['question']}\")\n",
        "    print(f\"A: {education_dataset[i]['expected_response']}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQlZzfVGvuVA",
        "outputId": "a4442df5-2f5f-4a33-854b-b2c82f6cd30c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Education dataset created with 7 samples\n",
            "\n",
            "Sample data:\n",
            "Q: What is photosynthesis?\n",
            "A: Photosynthesis is the process where plants use sunlight, water and carbon dioxide to create oxygen and energy in the form of sugar.\n",
            "\n",
            "Q: Solve 2x + 5 = 15\n",
            "A: First, subtract 5 from both sides: 2x = 10. Then divide both sides by 2: x = 5\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Initialize Language Model"
      ],
      "metadata": {
        "id": "4ciFzEJOzW3L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EducationLanguageModel:\n",
        "    def __init__(self):\n",
        "        self.model_name = \"microsoft/DialoGPT-small\"\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
        "\n",
        "        if self.tokenizer.pad_token is None:\n",
        "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "\n",
        "        self.model = AutoModelForCausalLM.from_pretrained(self.model_name)\n",
        "        self.similarity_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model = self.model.to(self.device)\n",
        "        print(f\"Model loaded on: {self.device}\")\n",
        "\n",
        "    def generate_response(self, question, max_length=100):\n",
        "        try:\n",
        "            inputs = self.tokenizer.encode(question + self.tokenizer.eos_token,\n",
        "                                         return_tensors='pt').to(self.device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model.generate(\n",
        "                    inputs,\n",
        "                    max_length=len(inputs[0]) + max_length,\n",
        "                    num_return_sequences=1,\n",
        "                    temperature=0.8,\n",
        "                    do_sample=True,\n",
        "                    pad_token_id=self.tokenizer.eos_token_id,\n",
        "                    attention_mask=torch.ones_like(inputs)\n",
        "                )\n",
        "\n",
        "            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "            response = response.replace(question, \"\").strip()\n",
        "            return response\n",
        "        except Exception as e:\n",
        "            print(f\"Error in generation: {e}\")\n",
        "            return \"I'm not sure how to answer that yet.\"\n",
        "\n",
        "    def calculate_similarity(self, text1, text2):\n",
        "        try:\n",
        "            embeddings = self.similarity_model.encode([text1, text2])\n",
        "            similarity = util.cos_sim(embeddings[0], embeddings[1])\n",
        "            return similarity.item()\n",
        "        except:\n",
        "            return 0.0\n",
        "\n",
        "# Initialize the language model\n",
        "lm_model = EducationLanguageModel()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_M9AJ-1zRaU",
        "outputId": "04829a6a-3096-40f5-e802-719912ae37e1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded on: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Create Custom Gym Environment"
      ],
      "metadata": {
        "id": "ytJleeypzi9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EducationEnv(gym.Env):\n",
        "    \"\"\"Custom Gym environment for educational text generation\"\"\"\n",
        "\n",
        "    def __init__(self, language_model, dataset):\n",
        "        super(EducationEnv, self).__init__()\n",
        "\n",
        "        self.language_model = language_model\n",
        "        self.dataset = dataset\n",
        "        self.current_idx = 0\n",
        "        self.step_count = 0\n",
        "        self.max_steps = 5\n",
        "\n",
        "        # Define action and observation space\n",
        "        # Action space: token indices (simplified for demo)\n",
        "        self.action_space = gym.spaces.Box(\n",
        "            low=0, high=language_model.tokenizer.vocab_size-1,\n",
        "            shape=(50,), dtype=np.int32\n",
        "        )\n",
        "\n",
        "        # Observation space: question embedding\n",
        "        self.observation_space = gym.spaces.Box(\n",
        "            low=-np.inf, high=np.inf, shape=(384,), dtype=np.float32\n",
        "        )\n",
        "\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.current_idx = (self.current_idx + 1) % len(self.dataset)\n",
        "        self.current_data = self.dataset[self.current_idx]\n",
        "        self.step_count = 0\n",
        "\n",
        "        # Get question embedding as observation\n",
        "        question_embedding = self.language_model.similarity_model.encode(\n",
        "            self.current_data['question']\n",
        "        )\n",
        "\n",
        "        return question_embedding.astype(np.float32)\n",
        "\n",
        "    def step(self, action):\n",
        "        self.step_count += 1\n",
        "\n",
        "        # Convert action to text (simplified - in practice you'd use the actual generation)\n",
        "        try:\n",
        "            # For demo purposes, we'll use the language model to generate response\n",
        "            # but in real RL, the action would directly control the generation\n",
        "            generated_response = self.language_model.generate_response(\n",
        "                self.current_data['question']\n",
        "            )\n",
        "        except:\n",
        "            generated_response = \"\"\n",
        "\n",
        "        # Calculate reward\n",
        "        reward = self._calculate_reward(generated_response)\n",
        "\n",
        "        # Check if episode is done\n",
        "        done = self.step_count >= self.max_steps\n",
        "\n",
        "        # Get next observation\n",
        "        next_obs = self.reset() if done else self._get_observation()\n",
        "\n",
        "        info = {\n",
        "            'question': self.current_data['question'],\n",
        "            'generated_response': generated_response,\n",
        "            'expected_response': self.current_data['expected_response'],\n",
        "            'similarity': self.reward_components['similarity']\n",
        "        }\n",
        "\n",
        "        return next_obs, reward, done, info\n",
        "\n",
        "    def _calculate_reward(self, generated_response):\n",
        "        expected_response = self.current_data['expected_response']\n",
        "\n",
        "        # 1. Semantic similarity (main component)\n",
        "        similarity = self.language_model.calculate_similarity(\n",
        "            generated_response, expected_response\n",
        "        )\n",
        "\n",
        "        # 2. Length appropriateness\n",
        "        response_length = len(generated_response.split())\n",
        "        length_score = max(0, 1 - abs(response_length - 40) / 80)\n",
        "\n",
        "        # 3. Keyword presence\n",
        "        question_words = set(self.current_data['question'].lower().split()[:3])\n",
        "        response_words = set(generated_response.lower().split())\n",
        "        keyword_score = len(question_words.intersection(response_words)) / len(question_words) if question_words else 0.3\n",
        "\n",
        "        # Combined reward\n",
        "        total_reward = 0.7 * similarity + 0.15 * length_score + 0.15 * keyword_score\n",
        "\n",
        "        self.reward_components = {\n",
        "            'similarity': similarity,\n",
        "            'length': length_score,\n",
        "            'keywords': keyword_score\n",
        "        }\n",
        "\n",
        "        return total_reward\n",
        "\n",
        "    def _get_observation(self):\n",
        "        question_embedding = self.language_model.similarity_model.encode(\n",
        "            self.current_data['question']\n",
        "        )\n",
        "        return question_embedding.astype(np.float32)\n",
        "\n",
        "    def render(self, mode='human'):\n",
        "        print(f\"Question: {self.current_data['question']}\")\n",
        "        print(f\"Expected: {self.current_data['expected_response']}\")\n",
        "\n",
        "# Create environment\n",
        "env = DummyVecEnv([lambda: EducationEnv(lm_model, education_dataset)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpomDTn1zai1",
        "outputId": "7f4c3ce2-81ee-4846-85bf-7cd51bc410fe"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Custom PPO Training with Stable-Baselines3"
      ],
      "metadata": {
        "id": "RtsK3xg_0V_j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainingCallback(BaseCallback):\n",
        "    def __init__(self, check_freq=100, verbose=1):\n",
        "        super(TrainingCallback, self).__init__(verbose)\n",
        "        self.check_freq = check_freq\n",
        "        self.rewards = []\n",
        "\n",
        "    def _on_step(self):\n",
        "        if self.n_calls % self.check_freq == 0:\n",
        "            if len(self.model.ep_info_buffer) > 0:\n",
        "                mean_reward = np.mean([ep_info['r'] for ep_info in self.model.ep_info_buffer])\n",
        "                self.rewards.append(mean_reward)\n",
        "                print(f\"Step {self.n_calls}, Mean Reward: {mean_reward:.3f}\")\n",
        "\n",
        "                # Test the model\n",
        "                if hasattr(self, 'test_model'):\n",
        "                    self.test_model()\n",
        "\n",
        "        return True\n",
        "\n",
        "    def test_model(self):\n",
        "        print(\"\\n--- Testing Current Model ---\")\n",
        "        test_env = EducationEnv(lm_model, education_dataset)\n",
        "        obs = test_env.reset()\n",
        "\n",
        "        for i in range(2):  # Test 2 questions\n",
        "            action = np.random.randint(0, lm_model.tokenizer.vocab_size-1, (50,))\n",
        "            obs, reward, done, info = test_env.step(action)\n",
        "\n",
        "            print(f\"Test {i+1}:\")\n",
        "            print(f\"Q: {info['question']}\")\n",
        "            print(f\"A: {info['generated_response'][:80]}...\")\n",
        "            print(f\"Similarity: {info['similarity']:.3f}\")\n",
        "            print(f\"Reward: {reward:.3f}\\n\")\n",
        "\n",
        "            if done:\n",
        "                obs = test_env.reset()\n",
        "\n",
        "def train_with_ppo():\n",
        "    \"\"\"Train using Stable-Baselines3 PPO\"\"\"\n",
        "\n",
        "    print(\"Starting PPO Training with Stable-Baselines3...\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # PPO configuration\n",
        "    model = PPO(\n",
        "        \"MlpPolicy\",\n",
        "        env,\n",
        "        learning_rate=1e-4,\n",
        "        n_steps=256,\n",
        "        batch_size=64,\n",
        "        n_epochs=10,\n",
        "        gamma=0.99,\n",
        "        gae_lambda=0.95,\n",
        "        clip_range=0.2,\n",
        "        ent_coef=0.01,\n",
        "        verbose=1,\n",
        "        tensorboard_log=\"./ppo_education_tensorboard/\"\n",
        "    )\n",
        "\n",
        "    # Create callback\n",
        "    callback = TrainingCallback(check_freq=50)\n",
        "\n",
        "    # Train the model\n",
        "    total_timesteps = 2000  # Reduced for demo purposes\n",
        "\n",
        "    print(f\"Training for {total_timesteps} timesteps...\")\n",
        "    model.learn(\n",
        "        total_timesteps=total_timesteps,\n",
        "        callback=callback,\n",
        "        log_interval=50\n",
        "    )\n",
        "\n",
        "    print(\"Training completed!\")\n",
        "    return model, callback.rewards\n",
        "\n",
        "# Start training\n",
        "trained_model, rewards_history = train_with_ppo()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCPyUec4zkl0",
        "outputId": "9c183be6-e530-49a3-8095-60749ddfb3b9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting PPO Training with Stable-Baselines3...\n",
            "============================================================\n",
            "Using cpu device\n",
            "Training for 2000 timesteps...\n",
            "Logging to ./ppo_education_tensorboard/PPO_1\n",
            "Training completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Simplified PPO Implementation (If SB3 has issues)"
      ],
      "metadata": {
        "id": "5uNw5NR50oMu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimplePPOTrainer:\n",
        "    \"\"\"Simplified PPO implementation for education task\"\"\"\n",
        "\n",
        "    def __init__(self, language_model, learning_rate=1e-5):\n",
        "        self.language_model = language_model\n",
        "        self.optimizer = torch.optim.AdamW(language_model.model.parameters(), lr=learning_rate)\n",
        "\n",
        "    def compute_advantages(self, rewards, values, gamma=0.99, gae_lambda=0.95):\n",
        "        \"\"\"Compute advantages using Generalized Advantage Estimation\"\"\"\n",
        "        advantages = []\n",
        "        advantage = 0\n",
        "\n",
        "        for t in reversed(range(len(rewards))):\n",
        "            delta = rewards[t] + gamma * values[t + 1] - values[t] if t < len(rewards) - 1 else 0\n",
        "            advantage = delta + gamma * gae_lambda * advantage\n",
        "            advantages.insert(0, advantage)\n",
        "\n",
        "        return torch.tensor(advantages)\n",
        "\n",
        "    def train_step(self, questions, generated_responses, expected_responses, rewards, epsilon=0.2):\n",
        "        \"\"\"Single PPO training step\"\"\"\n",
        "\n",
        "        losses = []\n",
        "\n",
        "        for i, question in enumerate(questions):\n",
        "            # Get the probability of generating the response\n",
        "            full_text = question + \" \" + generated_responses[i]\n",
        "            inputs = self.language_model.tokenizer.encode(full_text, return_tensors='pt')\n",
        "            inputs = inputs.to(self.language_model.device)\n",
        "\n",
        "            # Forward pass with gradients\n",
        "            outputs = self.language_model.model(inputs, labels=inputs)\n",
        "            current_loss = outputs.loss\n",
        "\n",
        "            # Simple PPO update (simplified)\n",
        "            advantage = torch.tensor(rewards[i], device=self.language_model.device)\n",
        "\n",
        "            # Policy gradient loss\n",
        "            policy_loss = -current_loss * advantage\n",
        "\n",
        "            losses.append(policy_loss)\n",
        "\n",
        "        # Backward pass\n",
        "        if losses:\n",
        "            total_loss = torch.stack(losses).mean()\n",
        "            self.optimizer.zero_grad()\n",
        "            total_loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(self.language_model.model.parameters(), max_norm=1.0)\n",
        "            self.optimizer.step()\n",
        "\n",
        "        return total_loss.item() if losses else 0.0\n",
        "\n",
        "def simple_training_loop():\n",
        "    \"\"\"Simple training loop without complex RL dependencies\"\"\"\n",
        "\n",
        "    print(\"Starting Simplified Training Loop...\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    trainer = SimplePPOTrainer(lm_model)\n",
        "\n",
        "    num_epochs = 5\n",
        "    episodes_per_epoch = 10\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_rewards = []\n",
        "        epoch_losses = []\n",
        "\n",
        "        print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        for episode in range(episodes_per_epoch):\n",
        "            # Sample random question\n",
        "            idx = random.randint(0, len(education_dataset) - 1)\n",
        "            data = education_dataset[idx]\n",
        "\n",
        "            question = data['question']\n",
        "            expected = data['expected_response']\n",
        "\n",
        "            # Generate response\n",
        "            generated = lm_model.generate_response(question)\n",
        "\n",
        "            # Calculate reward\n",
        "            similarity = lm_model.calculate_similarity(generated, expected)\n",
        "            reward = similarity  # Simple reward based on similarity\n",
        "\n",
        "            # Training step (simplified)\n",
        "            loss = trainer.train_step([question], [generated], [expected], [reward])\n",
        "\n",
        "            epoch_rewards.append(reward)\n",
        "            epoch_losses.append(loss)\n",
        "\n",
        "            if episode % 2 == 0:\n",
        "                print(f\"Episode {episode + 1}:\")\n",
        "                print(f\"Q: {question}\")\n",
        "                print(f\"A: {generated[:60]}...\")\n",
        "                print(f\"Similarity: {similarity:.3f}, Loss: {loss:.4f}\")\n",
        "                print(\"-\" * 30)\n",
        "\n",
        "        # Epoch summary\n",
        "        avg_reward = np.mean(epoch_rewards)\n",
        "        avg_loss = np.mean(epoch_losses)\n",
        "\n",
        "        print(f\"\\nEpoch {epoch + 1} Summary:\")\n",
        "        print(f\"Average Reward: {avg_reward:.3f}\")\n",
        "        print(f\"Average Loss: {avg_loss:.4f}\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "# Run simplified training\n",
        "simple_training_loop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRymjmvE0XzQ",
        "outputId": "6c3f92c8-1f1b-4afe-a1fa-87d494e922e0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Simplified Training Loop...\n",
            "============================================================\n",
            "\n",
            "Epoch 1/5\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 1:\n",
            "Q: What is the Pythagorean theorem?\n",
            "A: It's not even the third quarter yet....\n",
            "Similarity: 0.032, Loss: -0.1610\n",
            "------------------------------\n",
            "Episode 3:\n",
            "Q: Solve 2x + 5 = 15\n",
            "A: what is the formula?...\n",
            "Similarity: 0.226, Loss: -2.7597\n",
            "------------------------------\n",
            "Episode 5:\n",
            "Q: How do plants reproduce?\n",
            "A: This is what happens when you don't let plants reproduce....\n",
            "Similarity: 0.555, Loss: -2.8958\n",
            "------------------------------\n",
            "Episode 7:\n",
            "Q: Explain the water cycle\n",
            "A: What??? I thought water was from our stomachs?...\n",
            "Similarity: 0.246, Loss: -2.5012\n",
            "------------------------------\n",
            "Episode 9:\n",
            "Q: Solve 2x + 5 = 15\n",
            "A: 3 : 5 1 :5 2 : 5 3 : 5...\n",
            "Similarity: 0.327, Loss: -3.1901\n",
            "------------------------------\n",
            "\n",
            "Epoch 1 Summary:\n",
            "Average Reward: 0.321\n",
            "Average Loss: -2.2585\n",
            "==================================================\n",
            "\n",
            "Epoch 2/5\n",
            "----------------------------------------\n",
            "Episode 1:\n",
            "Q: What is photosynthesis?\n",
            "A: It's a form of photosynthesis....\n",
            "Similarity: 0.755, Loss: -4.8794\n",
            "------------------------------\n",
            "Episode 3:\n",
            "Q: What is photosynthesis?\n",
            "A: Photynthesis. It's in the name....\n",
            "Similarity: 0.450, Loss: -4.1146\n",
            "------------------------------\n",
            "Episode 5:\n",
            "Q: How do plants reproduce?\n",
            "A: You could say this for any animal, any shape of life....\n",
            "Similarity: 0.119, Loss: -0.8697\n",
            "------------------------------\n",
            "Episode 7:\n",
            "Q: Explain the water cycle\n",
            "A: It was more of a water cycle than an earthquake, but yeah th...\n",
            "Similarity: 0.426, Loss: -2.0884\n",
            "------------------------------\n",
            "Episode 9:\n",
            "Q: Solve 2x + 5 = 15\n",
            "A: 1. Find the nearest number 2. Count down from now until the ...\n",
            "Similarity: 0.187, Loss: -1.8105\n",
            "------------------------------\n",
            "\n",
            "Epoch 2 Summary:\n",
            "Average Reward: 0.326\n",
            "Average Loss: -2.2457\n",
            "==================================================\n",
            "\n",
            "Epoch 3/5\n",
            "----------------------------------------\n",
            "Episode 1:\n",
            "Q: What is the Pythagorean theorem?\n",
            "A: I mean, hypothetically, if there was an earthquake during th...\n",
            "Similarity: 0.033, Loss: -0.1725\n",
            "------------------------------\n",
            "Episode 3:\n",
            "Q: Solve 2x + 5 = 15\n",
            "A: 1. Andrew 2. Andrew 3. Andrew...\n",
            "Similarity: 0.098, Loss: -2.0176\n",
            "------------------------------\n",
            "Episode 5:\n",
            "Q: How do plants reproduce?\n",
            "A: I like the way this guy thinks....\n",
            "Similarity: -0.036, Loss: 0.4397\n",
            "------------------------------\n",
            "Episode 7:\n",
            "Q: What causes seasons on Earth?\n",
            "A: I wonder if he had any weather related events...\n",
            "Similarity: 0.150, Loss: -0.9526\n",
            "------------------------------\n",
            "Episode 9:\n",
            "Q: What is Newton's first law of motion?\n",
            "A: I bet that guy is still rolling over in his grave, looking a...\n",
            "Similarity: 0.142, Loss: -0.7893\n",
            "------------------------------\n",
            "\n",
            "Epoch 3 Summary:\n",
            "Average Reward: 0.204\n",
            "Average Loss: -1.9825\n",
            "==================================================\n",
            "\n",
            "Epoch 4/5\n",
            "----------------------------------------\n",
            "Episode 1:\n",
            "Q: What is Newton's first law of motion?\n",
            "A: I like the way you move the camera...\n",
            "Similarity: 0.114, Loss: -0.6873\n",
            "------------------------------\n",
            "Episode 3:\n",
            "Q: Solve 2x + 5 = 15\n",
            "A: 12...\n",
            "Similarity: 0.199, Loss: -6.4968\n",
            "------------------------------\n",
            "Episode 5:\n",
            "Q: How do plants reproduce?\n",
            "A: But how did he get that?...\n",
            "Similarity: 0.119, Loss: -1.2892\n",
            "------------------------------\n",
            "Episode 7:\n",
            "Q: What is Newton's first law of motion?\n",
            "A: You should see my first Newton....\n",
            "Similarity: 0.395, Loss: -3.3944\n",
            "------------------------------\n",
            "Episode 9:\n",
            "Q: What is the Pythagorean theorem?\n",
            "A: I hate myself, but I'm going to give it a shot....\n",
            "Similarity: -0.012, Loss: 0.0906\n",
            "------------------------------\n",
            "\n",
            "Epoch 4 Summary:\n",
            "Average Reward: 0.174\n",
            "Average Loss: -1.8780\n",
            "==================================================\n",
            "\n",
            "Epoch 5/5\n",
            "----------------------------------------\n",
            "Episode 1:\n",
            "Q: What is the Pythagorean theorem?\n",
            "A: I don't get it...\n",
            "Similarity: 0.131, Loss: -1.0805\n",
            "------------------------------\n",
            "Episode 3:\n",
            "Q: What causes seasons on Earth?\n",
            "A: It is season....\n",
            "Similarity: 0.507, Loss: -5.7220\n",
            "------------------------------\n",
            "Episode 5:\n",
            "Q: What causes seasons on Earth?\n",
            "A: Yeah, but it's summer, and there's no wind....\n",
            "Similarity: 0.435, Loss: -3.7230\n",
            "------------------------------\n",
            "Episode 7:\n",
            "Q: Solve 2x + 5 = 15\n",
            "A: 14 17...\n",
            "Similarity: 0.142, Loss: -4.6994\n",
            "------------------------------\n",
            "Episode 9:\n",
            "Q: What is photosynthesis?\n",
            "A: I'm not a plant....\n",
            "Similarity: 0.286, Loss: -4.4833\n",
            "------------------------------\n",
            "\n",
            "Epoch 5 Summary:\n",
            "Average Reward: 0.213\n",
            "Average Loss: -2.9197\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Evaluation and Testing"
      ],
      "metadata": {
        "id": "QmCC9H1403vQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model():\n",
        "    \"\"\"Comprehensive model evaluation\"\"\"\n",
        "\n",
        "    print(\"üß™ MODEL EVALUATION\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    test_questions = [\n",
        "        \"What is photosynthesis?\",\n",
        "        \"How do plants make food?\",\n",
        "        \"Explain gravity simply\",\n",
        "        \"What is 8 √ó 7?\",\n",
        "        \"Why do we have seasons?\"\n",
        "    ]\n",
        "\n",
        "    similarities = []\n",
        "\n",
        "    for i, question in enumerate(test_questions, 1):\n",
        "        response = lm_model.generate_response(question)\n",
        "\n",
        "        # For evaluation, we'll calculate similarity with expected patterns\n",
        "        if \"photosynthesis\" in question.lower():\n",
        "            expected_keywords = [\"sunlight\", \"plants\", \"carbon\", \"oxygen\", \"energy\"]\n",
        "        elif \"food\" in question.lower():\n",
        "            expected_keywords = [\"photosynthesis\", \"sunlight\", \"energy\", \"plants\"]\n",
        "        elif \"gravity\" in question.lower():\n",
        "            expected_keywords = [\"force\", \"pull\", \"earth\", \"mass\"]\n",
        "        elif \"8 √ó 7\" in question or \"8*7\" in question:\n",
        "            expected_keywords = [\"56\"]\n",
        "        elif \"seasons\" in question.lower():\n",
        "            expected_keywords = [\"tilt\", \"axis\", \"earth\", \"sun\", \"orbit\"]\n",
        "        else:\n",
        "            expected_keywords = []\n",
        "\n",
        "        # Calculate keyword-based score\n",
        "        keyword_score = sum(1 for kw in expected_keywords if kw in response.lower()) / len(expected_keywords) if expected_keywords else 0.5\n",
        "\n",
        "        # Calculate length score\n",
        "        length_score = min(1.0, len(response.split()) / 30)\n",
        "\n",
        "        overall_score = 0.7 * keyword_score + 0.3 * length_score\n",
        "        similarities.append(overall_score)\n",
        "\n",
        "        print(f\"Test {i}:\")\n",
        "        print(f\"Q: {question}\")\n",
        "        print(f\"A: {response}\")\n",
        "        print(f\"Score: {overall_score:.3f}\")\n",
        "        print(f\"Length: {len(response.split())} words\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "    # Final evaluation\n",
        "    avg_score = np.mean(similarities)\n",
        "    print(f\"\\nüìä FINAL EVALUATION:\")\n",
        "    print(f\"Average Score: {avg_score:.3f}\")\n",
        "\n",
        "    if avg_score > 0.7:\n",
        "        print(\"‚úÖ EXCELLENT - Model is performing well!\")\n",
        "    elif avg_score > 0.5:\n",
        "        print(\"‚úÖ GOOD - Model is learning!\")\n",
        "    elif avg_score > 0.3:\n",
        "        print(\"‚ö†Ô∏è FAIR - Needs more training\")\n",
        "    else:\n",
        "        print(\"‚ùå POOR - Significant improvement needed\")\n",
        "\n",
        "# Run evaluation\n",
        "evaluate_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9Jd7mS101R4",
        "outputId": "5c720f18-d466-47c6-9e3f-4ac2bec87121"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üß™ MODEL EVALUATION\n",
            "============================================================\n",
            "Test 1:\n",
            "Q: What is photosynthesis?\n",
            "A: It's so simple.\n",
            "Score: 0.030\n",
            "Length: 3 words\n",
            "--------------------------------------------------\n",
            "Test 2:\n",
            "Q: How do plants make food?\n",
            "A: Why did you go into your computer and open a new tab??\n",
            "Score: 0.120\n",
            "Length: 12 words\n",
            "--------------------------------------------------\n",
            "Test 3:\n",
            "Q: Explain gravity simply\n",
            "A: They're so cool.\n",
            "Score: 0.030\n",
            "Length: 3 words\n",
            "--------------------------------------------------\n",
            "Test 4:\n",
            "Q: What is 8 √ó 7?\n",
            "A: If you don't have any interest in 8, why would you want to read it?\n",
            "Score: 0.150\n",
            "Length: 15 words\n",
            "--------------------------------------------------\n",
            "Test 5:\n",
            "Q: Why do we have seasons?\n",
            "A: No. Please no.\n",
            "Score: 0.030\n",
            "Length: 3 words\n",
            "--------------------------------------------------\n",
            "\n",
            "üìä FINAL EVALUATION:\n",
            "Average Score: 0.072\n",
            "‚ùå POOR - Significant improvement needed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Interactive Demo"
      ],
      "metadata": {
        "id": "muy9UHRu1lSE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def interactive_demo():\n",
        "    \"\"\"Interactive chat with the educated model\"\"\"\n",
        "\n",
        "    print(\"ü§ñ EDUCATION TUTOR DEMO\")\n",
        "    print(\"Type 'quit' to exit the demo\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    while True:\n",
        "        question = input(\"\\nüßë‚Äçüéì Student: \").strip()\n",
        "\n",
        "        if question.lower() in ['quit', 'exit', 'bye']:\n",
        "            print(\"ü§ñ Tutor: Goodbye! Keep learning!\")\n",
        "            break\n",
        "\n",
        "        if not question:\n",
        "            continue\n",
        "\n",
        "        response = lm_model.generate_response(question)\n",
        "        print(f\"ü§ñ Tutor: {response}\")\n",
        "\n",
        "# Start interactive demo\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üöÄ STARTING INTERACTIVE EDUCATION TUTOR\")\n",
        "print(\"=\"*60)\n",
        "interactive_demo()"
      ],
      "metadata": {
        "id": "pBdZvyT7053o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}